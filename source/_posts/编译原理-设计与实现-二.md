---
title: 编译原理-设计与实现-二
date: 2022-01-24 12:38:15
tags: ['手写','编译原理']
categories: ['手写']
---

# 前言

  本篇博客记录**语法分析**部分，并且完成**Programming Assignment III**

## Syntax Analysis/Parsing

  语法分析是编译器的第二个阶段。语法分析器从词法分析器获得一个由词法单元组成的串，并验证这个串可以由源语言的文法生成


## Context-Free Grammars

  一个上下文无关文法由以下几个部分构成
  1. 一个**终结符号**集合。在编译器的例子中，就是**词法分析器**输出的**词法单元**集合
  2. 一个**非终结符**集合。每个**非终结符**表示一个**终结符号**串的集合
  3. 一个**产生式**集合。其中每个**产生式**由如下元素组成：
    - 一个称为**产生式头**或**左部**的非终结符号
    - 一个箭头$$\rightarrow$$
    - 一个称为**产生式体**或**右部**的，由**终结符号**和**非终结符号**组成的序列
  4. 指定一个**非终结符号**为**开始符号**

  上下文无关文法的表达能力比正则表达式更强——每个可以使用正则表达式描述的构造都可以使用上下文无关文法描述，但反过来不成立。诸如**括号嵌套匹配**等问题，上下文无关文法可以解决，然而正则表达式无法解决
  虽然如此，其在处理不同问题时有不同优势。在编译器的例子中，**正则表达式**适合描述诸如标识符、常量、关键字、空白这样的语言构造的结构，也就是**词法分析**；而**上下文无关文法**适合描述诸如对称的括号匹配、匹配的begin-end、相互对应的if-then-else等，也就是**语法分析**。

  目前，主流的处理**上下文无关文法**的方式有以下两种
  - Top-Down Parsing，即自顶向下
  - Bottom-Up Parsing，即自底向上

### Top-Down Parsing

  实际上，**自顶向下**语法分析，可以被看作是为**输入串**构造语法分析树，也可以看作寻找输入串的**最左推导**的过程
  其中，最常用的是**LL(1)**算法进行处理，即**Left-to-right-scan Leftmost-derivation One-token-lookahead**，其设计**FIRST**集合和**FOLLOW**集合


#### FIRST集合

  $FIRST(A)$被定义为可从$$A$$推导得到的**串**的首符号的集合，其中$$A$$是任意的**非终结符号**

  也就是对于任意的**非终结符号**$$A$$，$$FIRST(A) = \{t|A \stackrel{*}{\rightarrow} t\omega, \omega为任意符号\}$$

  遍历**非终结符号**$$A$$的所有的**产生式**，并通过如下步骤计算$$FIRST(A)$$
  - 若有$$A \rightarrow \alpha$$，则有$$FIRST(A) = FIRST(A) \cup \{\alpha\}$$
  - 若有$$A \rightarrow \alpha B，B为任意符号$$，则有$$FIRST(A) = FIRST(A) \cup \{\alpha\}$$
  
#### FOLLOW集合

  $FOLLOW(A)$被定义为可能在某些句型中紧跟在$$A$$右边的终结符号的集合，其中$$A$$是任意的**非终结符号**

  也就是对于任意的**非终结符号**$$A$$，$$FOLLOW(A) = \{t|A \stackrel{*}{\rightarrow} \alpha At \omega, \alpha、\omega为任意符号\}$$

  遍历所有的**产生式**，并通过如下步骤计算$$FOLLOW(A)$$
  - 若有$$B \rightarrow \alpha At \omega，\alpha、\omega为任意符号$$，则有$$FOLLOW(A) = FOLLOW(A) \cup \{t\}$$
  - 若有$$B \rightarrow \alpha A \omega，\alpha为任意符号，\omega为非终结符号$$，则有$$FOLLOW(A) = FOLLOW(A) \cup FIRST(\omega)$$
  - 若有$$B \rightarrow \alpha A \omega，\alpha为任意符号，\omega为非终结符号$$，且$$\epsilon \in FIRST(\omega)$$，则有$$FOLLOW(A) = FOLLOW(A) \cup FOLLOW(B)$$


#### LL(1)表

  实际上，并非任意上下文无关文法都可以使用**LL(1)**算法。对于文法**G**，其需要满足如下条件
  1. 对于**G**的任意两个不同的产生式$$A \rightarrow \alpha | \beta$$，不存在**终结符号**a，使得$$\alpha$$和$$\beta$$都能够推导出以a开头的串
  2. 对于**G**的任意两个不同的产生式$$A \rightarrow \alpha | \beta$$，最多只有一个可以推导出空串
  3. 对于**G**的任意两个不同的产生式$$A \rightarrow \alpha | \beta$$。如果$$\beta \stackrel{*}{\rightarrow} \epsilon$$，那么a不能推导出任何以$$FOLLOW(A)$$中某个**终结符号**开头的串

  实际上，通过上述条件的约束，其确保了对于任意两个不同的产生式$$A \rightarrow \alpha | \beta$$，$$FIRST(A) \cap FIRST(B) = \varnothing $$。
  也就是仅仅通过判断紧挨着的**一个**输入字符，即可**唯一**选择一个产生式并进行推导，也就是可以**查表**实现推导规则的选择

  而**LL(1)**的表可以通过如下规则，构造文法**G**的表**M**:
  对于文法**G**的每个产生式$$A \rightarrow \alpha$$
  1. 对于$$FIRST(\alpha)$$中的每一个终结符号a，将$$A \rightarrow \alpha$$加入到**M[A, a]**中
  2. 如果$$\epsilon \in FIRST(\alpha)$$，则对于$$FOLLOW(A)$$中的每个终结符号b，将$$A \rightarrow \alpha$$加入到**M[A, b]**中
  3. 如果$$\epsilon \in FIRST(\alpha)$$，且$$\$ \in FOLLOW(A)$$，将$$A \rightarrow \alpha$$加入到**M[A, $]**中

  当将**LL(1)**表构造出来后，其验证串的算法就非常简单了，算法如下所示
  ```
stack <- {}
while(stack.size()) {
    if(stack.top() is terminal) {
        if(stack.pop() == *input++) {}
        else {error();}
    }else {
        if(M[stack.top(), *input]) {
            stack.push(M[stack.pop(), *input]);
        }else {error();}
    }
}
```

  ![LL1样例](LL1样例.png)

### Bottom-Up Parsing

  简单来说，可以将**自底向上**语法分析过程看成将一个串$$\omega$$**规约**为上下文无关文法的开始符号的过程，也可以看作寻找输入串**最右推导**的逆向过程
  实践中使用**LR(0)**语法分析器，即**Left-to-right-scan Rightmost-derivation Zero-token-lookahead**，实现自底向上的语法分析，这里简单讲解**LR(0)**语法分析技术，其涉及到**Shift-Reduce Parsing**、**CLOSURE**、**GOTO**、**Simple LR**等概念

#### Shift-Reduce Parsing

  **移入-规约语法分析技术**是自底向上语法分析的通用框架，由以下几个部分构成:
  1. 一个**栈**，其用来保存上下文无关文法的**符号**
  2. 一个**输入缓冲区**，即存放将要进行分析的上下文无关文法的**终结符号**
  3. 一系列**操作**
    - **移入(Shift)**：将下一个**输入缓冲区**的输入符号移动到**栈**顶
    - **规约(Reduce)**：将从栈顶开始的与某个**产生式体**匹配的子串**出栈**，并且将该**产生式头**入栈
    - 接受：当栈中只含有上下文无关文法的**开始符号**时，则分析过程成功
    - 报错：即**输入缓冲区**无输入，且无法进行**规约**操作
  
  ![Shift-Reduce样例](Shift-Reduce样例.png)

  因此，关键问题在于**何时**进行规约以及应用**哪个**产生式进行规约。可以通过**CLOSURE**、**GOTO**集合生成一个**LR**表，从而解决问题。


#### CLOSURE

  通过对上下文无关文法的**产生式**的**体**中添加点，从而生成所谓的**Item(项)**
  ![拓广文法 item样例](拓广文法item样例.png)

  而基于项的集合$$I$$，可以根据如下规则定义项集的闭包$$CLOSURE(I)$$
  1. 将$$I$$的各个项加入到$$CLOSURE(I)$$
  2. 如果$$A \rightarrow \alpha \cdot B \beta \in CLOSURE(I)$$，$$B \rightarrow \gamma$$是一个产生式，并且项$$B \rightarrow \cdot \gamma \notin CLOSURE(I)$$中，则将$$B \rightarrow \cdot \gamma$$加入到$$CLOSURE(I)$$。不断应用这个规则，直到没有新项可以加入为止

  实际上，对于$$A \rightarrow \alpha \cdot B \beta \in CLOSURE(I)$$，则认为接下来在输入中需要看到一个能够从$$B \beta$$推导的子串，也就是必然会用到$$B$$的产生式，将其加入到$$CLOSURE(I)$$中，从而得到基于该上下文无关文法的完备项集

#### GOTO

  $GOTO(I,X)$用于定义上下文无关文法的状态转换。其中$$I$$是一个项集；$$X$$是上下文无关文法的符号

  则$$GOTO(I, X) = \cup CLOSURE(\{[A \rightarrow \alpha X \cdot \beta] | [A \rightarrow \alpha \cdot X \beta] \in I\})$$


#### Simple LR

  类似于**LL(1)**，**SLR**同样可以构造一个分析表，从而根据该表完成上下文无关文法的识别

  通过如下规则，可以将一个上下文无关文法**G**，转换成**SLR**的表$$ACTION$$和$$GOTO^{'}$$
  1. 在**G**中，添加新的开始符号$$S^{'}$$，构成增广文法$$G^{'}$$
  2. 按照下列算法，构造$$G^{'}$$的规范**LR(0)**项集族$$C = \{I_{0}, I_{1}, \cdots, I_{n}\}$$
  ```
C = {CLOSURE({S' -> .S})}
while(true) {
  for(I in C) {
    for(X : 上下文无关文法符号) {
      if(GOTO(I, X)非空 && GOTO(I, X)不在C) {
        C.append(GOTO(I, X))
      }
    }
  }
}
```
  3. 根据$$I_{i}$$构造得到状态$$i$$
    - 如果$$[A \rightarrow \alpha \cdot a \beta] \in I_{i}$$，且$$GOTO(I_{i}, a) = I_{j}$$，则令$$ACTION[i, a] = S_{j}$$，其中a为**G**的终结符号。也就是接受输入a，并且移动到j状态
    - 如果$$[A \rightarrow \alpha \cdot] \in I_{i}$$，那么对于所有的$$FOLLOW(A)$$中所有终结符号a，令$$ACTION[i, a] = R_{A \rightarrow \alpha}$$，其中$$A \neq S^{'}$$
    - 如果$$[S^{'} \rightarrow S \cdot] \in I_{i}$$，则令$$ACTION[i, \$] = AC$$
  4. 对于状态i的非终结符号A，如果$$GOTO(I_{i}, A) = I_{j}$$，则$$GOTO^{'}[i, A] = j$$
  5. 规则(3)和(4)剩余的条目设置为ERR

  当获取了**SLR**的分析表后，可以使用如下算法，即基于**查找分析表**的**移入-规约语法分析**过程来判断是否为上下文无关文法语句
  ```
stack = {}
while(true) {
  X = stack.pop();

  if(ACTION[X, *input] = Sj) {
    stack.push(j);
    ++input;
  }else if(ACTION[X, *input] = Rf) {
    stack.push(GOTO'[X, f(产生式)的头])
    ++input;
  }else if(ACTION[X, *input)] = AC) {break;}
  else {error();}
}
```

  ![slr分析表](slr分析表.png)
  ![slr过程](slr过程.png)

# PA3 Syntax Analysis

## 实验描述

  在该实验中，需要通过编写**Bison**规则，从而完成**Cool**的语法分析，并且返回一个抽象语法树**(AST)**。

  需要注意的是，实现的语法分析器应该具有足够的鲁棒性——可以在任何输入下都正常工作，即可以处理错误

## 实验环境

  该实验中依赖**2.4**版本的**Bison**，和之前的**Flex**，则在`assignments/PA3`目录执行如下命令设置环境
  ```bash
sudo apt-get update \
  && sudo apt-get install -y m4 \
  && (cd ../../bin/flex; ./configure; make; sudo make install) \
  && (cd ../../bin/bison; ./configure; make; sudo make install)
```

## 实验实现

  下面是个人的思路及其[实现](https://gitee.com/jiaweihawk/stanford-compiler/tree/74dae99408996759f4046de1f75e41c0f5c6c70d/)

  实际上，这个实验就是定义解析**Cool**的**Bison**规则
  因此，需要了解**Bison**的使用方法——可以查看[Bison的手册](https://www.gnu.org/software/bison/manual/bison.html)。虽然版本不一致，但是整体并没有太大的区别。

### 词法规则

  实际上，根据手册，**Cool**中定义了如下的语法规则
  ![语法规则](语法规则.png)

  则将其转换为**Bison**规则即可，其中**program**和**class**已经存在了，则我们需要实现**feature**、**formal**和**expr**的规则即可

#### feature

  由于**feature**中涉及$$[formal[,formal]^*]$$，则其需要包含**零个**、**一个**和**多个**的**formal**的情况
  其中**一个**和**多个**的**formal**，使用实验环境中的**链表**结构表示即可，即**formal_list2**表示
  ```
%{
  ...
}%
    %type <features> dummy_feature_list
    %type <feature> feature
%%

    /* Feature list may be empty, but no empty features in list. */
    dummy_feature_list
    : feature                                          /* single feature */
    { $$ = single_Features($1); }
    | dummy_feature_list feature                       /* several features */
    { $$ = append_Features($1, single_Features($2)); }
    ;

    feature
    : OBJECTID '(' ')' ':' TYPEID '{' expression '}' ';'      /* 成员函数 */
    { $$ = method($1, nil_Formals(), $5, $7); }
    | OBJECTID formal_list2 ':' TYPEID '{' expression '}' ';' /* 成员函数 */
    { $$ = method($1, $2, $4, $6); }
    | OBJECTID ':' TYPEID ASSIGN expression ';'               /* 初始化成员变量 */
    { $$ = attr($1, $3, $5); }
    | OBJECTID ':' TYPEID ';'                                 /* 未初始化成员变量 */
    { $$ = attr($1, $3, no_expr()); }
    | OBJECTID error ';'                                  /* 成员函数错误处理 */
    { yyclearin; }
    ;
```

#### formal

  由于在**feature**中，包含$$[formal[,formal]^*]$$
  则根据上面实现的**feature**规则，我们需要实现$$formal[,formal]^*]$$的规则，如下所示
  ```
%{
  ...
}%
    /*
     * Precedence declarations go here.
     * formal_list1             [, formal]+
     * formal_list2             (formal[, formal]*)
     */
    %type <formals> formal_list1 formal_list2
    %type <formal> formal

%%

    /*
     * formal_list1             [, formal]+
     */
    formal_list1
    : formal                                                      /* single */
    { $$ = single_Formals($1); }
    | formal_list1 formal                                         /* serveral */
    { $$ = append_Formals($1, single_Formals($2)); }
    ;

    /*
     * formal_list2             (formal[, formal]*)
     */
    formal_list2
    : '(' OBJECTID ':' TYPEID ')'                                 /* single */
    { $$ = single_Formals(formal($2, $4)); }
    | '(' OBJECTID ':' TYPEID formal_list1 ')'                    /* several formals */
    { $$ = append_Formals(single_Formals(formal($2, $4)), $5); }
    ;


    formal
    : ',' OBJECTID ':' TYPEID
    { $$ = formal($2, $4); }
    ;
```

#### expr

  最后则是**expr**

  - 一方面，由于**expr**中多处包含诸如$$[expr[,expr]^*]$$、$$[expr;]^+$$、$$[,ID:TYPE[<- expr]]^*$$等
  这里通过类似于上面的，将其以**链表**形式管理即可，然后根据对应的**正则表达式**，设置**链表**的构建规则即可
  - 另一方面，为了避免**Bison**的**Shift/Reduce Conflicts**，通过设置运算符的优先级进行解决，手册中定义了**Cool**的运算符的优先级
  ![运算符的优先级](运算符的优先级.png)

  最终，**expr**的规则如下所示
  ```
%{
  ...
}%
    %type <cases> case_list
    %type <case_> case

    /*
     * expression_list1          expr[, expr]*
     * expression_list2          [expr;]+
    */
    %type <expressions> expression_list1 expression_list2
    %type <expression> expression expression_let
    

    /*
     * 通过声明优先级，尝试解决二义性问题
     */
    %right THEN ELSE                                      /* 尝试解决悬挂else问题 */
    %right ASSIGN IN                                      /* 尝试解决expression优先级问题 */
    %right NOT
    %nonassoc LE '<' '='
    %left '+' '-'
    %left '*' '/'
    %right ISVOID
    %right '~'
    %right '@'
    %right '.' 

%%

    case_list
    : case ';'                                                    /* single branch */
    { $$ = single_Cases($1); }
    | case_list case ';'                                          /* several branches */
    { $$ = append_Cases($1, single_Cases($2)); }
    ;

    case
    : OBJECTID ':' TYPEID DARROW expression
    { $$ = branch($1, $3, $5); }
    ;

    /*
     * expression_list1          expr[, expr]*
     */
    expression_list1
    : expression                                                    /* single expression */
    { $$ = single_Expressions($1); }
    | expression_list1 ',' expression                               /* several expressions */
    { $$ = append_Expressions($1, single_Expressions($3)); }


    /*
     * expression_list2          [expr;]+
     */
    expression_list2
    : expression ';'                                              /* single expression */
    { $$ = single_Expressions($1); }
    | expression_list2 expression ';'                              /* several expressions */
    { $$ = append_Expressions($1, single_Expressions($2)); }
    | expression_list2 error ';'                                  /* 错误处理 */
    { $$ = $1; }
    ;

    /*
     * expression_let            ID:TYPE [<- expr] [,ID:TYPE [<- expr]] in expr
     */
    expression_let
    : OBJECTID ':' TYPEID IN expression                           /* ID : TYPE in expr */
    { $$ = let($1, $3, no_expr(), $5); }
    | OBJECTID ':' TYPEID ASSIGN expression IN expression         /* ID : TYPE <- expr in expr */
    { $$ = let($1, $3, $5, $7); }
    | OBJECTID ':' TYPEID ',' expression_let                      /* ID : TYPE [, ID : TYPE [<- expr]]+ in expr */
    { $$ = let($1, $3, no_expr(), $5); }
    | OBJECTID ':' TYPEID ASSIGN expression ',' expression_let    /* ID : TYPE <- expr [, ID : TYPE [<- expr]]+ in expr */
    { $$ = let($1, $3, $5, $7); }
    | error ',' expression_let                                    /* 错误处理 */
    { $$ = $3; }
    ;

    expression
    : OBJECTID ASSIGN expression                                  /* ID <- expr */
    { $$ = assign($1, $3); }
    | expression '.' OBJECTID '(' ')'                             /* expr.ID([expr[, expr]*]) */
    { $$ = dispatch($1, $3, nil_Expressions()); }
    | expression '.' OBJECTID '(' expression_list1 ')'
    { $$ = dispatch($1, $3, $5); }
    | expression '@' TYPEID '.' OBJECTID '(' expression_list1 ')' /* expr@TYPE.ID([expr[, expr]*]) */
    { $$ = static_dispatch($1, $3, $5, $7); }
    | expression '@' TYPEID '.' OBJECTID '(' ')'
    { $$ = static_dispatch($1, $3, $5, nil_Expressions()); }
    | OBJECTID '(' expression_list1 ')'                           /* ID([expr[, expr]*]) */
    { $$ = dispatch(object(idtable.add_string("self")), $1, $3); }
    | OBJECTID '(' ')'
    { $$ = dispatch(object(idtable.add_string("self")), $1, nil_Expressions()); }
    | IF expression THEN expression ELSE expression FI            /* if expr then expr else expr fi */
    { $$ = cond($2, $4, $6); }
    | WHILE expression LOOP expression POOL                       /* while expr loop expr pool */
    { $$ = loop($2, $4); }
    | '{' expression_list2 '}'                                    /* {[expr;]+} */
    { $$ = block($2); }
    | LET expression_let                                          /* ID : TYPE <- expr [, ID : TYPE [<- expr]]+ in expr */
    { $$ = $2; }
    | CASE expression OF case_list ESAC                           /* typcase */ 
    { $$ = typcase($2, $4); }
    | NEW TYPEID                                                  /* new Type */
    { $$ = new_($2); }
    | ISVOID expression                                           /* isvoid expr */
    { $$ = isvoid($2); }
    | expression '+' expression                                   /* expr + expr */
    { $$ = plus($1, $3); }
    | expression '-' expression                                   /* expr - expr */
    { $$ = sub($1, $3); }
    | expression '*' expression                                   /* expr * expr */
    { $$ = mul($1, $3); }
    | expression '/' expression                                   /* expr / expr */
    { $$ = divide($1, $3); }
    | '~' expression                                              /* ~expr */
    { $$ = neg($2); }
    | expression '<' expression                                   /* expr < expr */
    { $$ = lt($1, $3); }
    | expression LE expression                                    /* expr <= expr */
    { $$ = leq($1, $3); }
    | expression '=' expression                                    /* expr = expr */
    { $$ = eq($1, $3); }
    | NOT expression                                              /* not expr */
    { $$ = comp($2); }
    | '(' expression ')'                                          /* (expr) */
    { $$ = $2; }
    | OBJECTID                                                    /* ID */
    { $$ = object($1); }
    | INT_CONST                                                   /* integer */
    { $$ = int_const($1); }
    | STR_CONST                                                   /* string */
    { $$ = string_const($1); }
    | BOOL_CONST                                                  /* true/false */
    { $$ = bool_const($1); }
    ;
```

### 错误恢复

  根据实验手册要求，当语法分析发现错误时，对于特定的情况需要恢复到正常情况
  1. **class**定义错误，但是其适当的闭合。则应该可以继续解析下一个**class**定义
  2. **feature**定义错误，但是其适当的闭合。则应该可以继续解析下一个**feature**
  3. **let**的绑定错误，但是有适当的分隔符**,**。则应该可以继续解析**let**的下一个绑定声明
  4. **block**定义错误，但是有适当的分隔符**;**。则应该可以继续解析**block**的下一个语句


  而实际上，错误恢复就是定义规则，并在规则中执行错误情况的动作，具体如下所示
  ```
%{
  ...
}%

%%

    class_list
    : ...
    | class_list error                                  /* 错误处理 */
    { $$ = $1; }
    ;

    class	
    : ...
    | CLASS error ';'                                  /* 类定义的错误处理 */
    { yyclearin; }
    ;

    feature
    : ...
    | OBJECTID error ';'                                  /* 成员函数错误处理 */
    { yyclearin; }
    ;

    /*
     * expression_list2          [expr;]+
     */
    expression_list2
    : ...
    | expression_list2 error ';'                                  /* 错误处理 */
    { $$ = $1; }
    ;

    /*
     * expression_let            ID:TYPE [<- expr] [,ID:TYPE [<- expr]] in expr
     */
    expression_let
    : ...
    | error ',' expression_let                                    /* 错误处理 */
    { $$ = $3; }
    ;
```

## 实验结果

### cmp.py

  为了观察自己实现的语法解析程序的效果，通过与标准的语法解析器的输出进行比较来实现

  这里还需要通过正则表达式过滤掉行号，因为标准的语法解析器行号有些不太正确
  程序的源代码如下所示
  ```python
import re
import sys

'''
参数1：            path         字符串，表明要读取的文件路径
返回值：                        列表，每一个元素表示一行的信息
读取制定文件的词法解析结果
即通过正则表达式，读取#[0-9]+ (.*)的的输入即可，其每一行的信息为(行号，内容)
'''
def read_lexical_result(path):
    res = []
    with open(path) as f:
        lines = f.readlines()
        for line in lines:
            result = re.match(r'#([0-9]+) (.*)$', line)
            if(result):
                res.append([result.group(1), result.group(2)])
    return res


if __name__ == '__main__':
    if(len(sys.argv) < 4):
        exit(-1)
    
    '''
        sys.argv[1]表示原始文件名称
        sys.argv[2]表示标准词法解析器的结果
        sys.argv[3]表示自己实现的词法解析器的结果
    '''
    lexer_output = read_lexical_result(sys.argv[2])
    mylexer_output = read_lexical_result(sys.argv[3])

    same_number = 0
    diff_result = []

    for i in range(len(lexer_output)):
        if(lexer_output[i][1] == mylexer_output[i][1]):
            same_number += 1
        else:
            diff_result.append([mylexer_output[i][0], lexer_output[i][1], mylexer_output[i][1]])

    print("\033[32;1m%s: %d/%d\033[0m"%(sys.argv[1], same_number, len(lexer_output)))
    for i in range(len(diff_result)):
        print('#%s: \033[32;1mlexer_output: %s; \033[31;1mmylexer_output: %s\033[0m'%(diff_result[i][0], diff_result[i][1], diff_result[i][2]))
    print('')
```

### Makefile

  更改**Makefile**中的**doteset**目标
  分别调用自己实现的语法解析器和标准的语法解析器，处理**./*cl**和**../../examples/*cl**，并调用前面实现的**cmp.py**，比较输出结果，从而进行测试

  修改的**Makefile**目标如下所示
  ```makefile
dotest:	parser good.cl
	for file in $$(find ../../examples/*.cl; find ./*.cl | grep -v bad.cl); do \
		basename=$$(echo $$file | awk -F / '{print $$NF}' | awk -F . '{print $$1}'); \
		../../bin/lexer $$file | ../../bin/parser > $$basename.syntax; \
		./myparser $$file > my$$basename.syntax; \
		python3 cmp.py $$basename $$basename.syntax my$$basename.syntax; \
	done

	for file in $$(find ./*.cl | grep bad.cl); do \
		basename=$$(echo $$file | awk -F / '{print $$NF}' | awk -F . '{print $$1}'); \
		../../bin/lexer $$file | ../../bin/parser 2>$$basename.syntax; \
		./myparser $$file 2>my$$basename.syntax; \
		python3 cmp.py $$basename $$basename.syntax my$$basename.syntax; \
	done
```

  最终，其运行结果如下所示
  ![实验结果](实验结果.png)